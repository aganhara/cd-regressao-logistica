# ===============================================================================================
# Curso: Introdução à Ciência de Dados e Decisões 


# Aula  - Modelos de Regressão Logística (R)

# Professor - Ricardo Augusto


# =========================
# Exercicio Computacional 1

# Objetivo: implementar modelos de regressão logística no R

# Pacote com inúmeros métodos/técnicas de ML para a linguagem R
library(caret)

# Pacote com funções que nos auxiliam a entender métricas de desempenho de classificadores
library(ROCR)

# Pacote cm diversas funções relacionadas a modelos de classificação 
library(e1071)

# Pacote para que possamos trabalhar com diversos datasets tradicionais como o Iris
library(datasets) 

# Pacote para sínteses estatísticas (summary) dos modelos
library(skimr)

# Pacote para processamento de dados do R
library(dplyr)

# Usamos esse pacote para realizar a binarização de variáveis de saída com a função to.dummy
library(varhandle)

# Pacote para que possamos explorar a matriz de correlação entre variáveis explanatórias
library(corrplot)


# Importação do dataset iris 
# data(iris)
# View(iris)

# Podemos verificar se não existe nenhum registro "na" no conjunto de dados 
# sum(is.na(iris))

# Para que possamos tornar os resultados reprodutíveis - vamos usar um seed com o valor 10
#set.seed(10)


# Síntese (summary) do conjunto de dados
# summary(iris)


# =====================================================================================================
# Como o dataset iris é limpo e preparado para a modelagem, vamos fazer iniciar com a divisão dos dados

# Atribuindo o dataset iris ao dataframe - dataset
dataset = iris

# Processando as classes para sua binarização do problema de classificação
# Objetivo: capturar as classes de interesse e atribuir 0 ou 1 para a espécie considerada no dataset
binary_species <- to.dummy(iris$Species, "species")
binary_species <- as.data.frame(binary_species)
unique(binary_species)

# Filtragem de Dados
# dataset <- subset(iris, Species == "virginica" | Species == 'versicolor') %>% droplevels()
# dataset <- subset(iris, Species == "virginica") %>% droplevels()

# Seleção da Espécie de interesse para o problema de classificação

# Espécies: setosa - versicolor - virginica
Species = binary_species$species.virginica
Species
dataset = data.frame(dataset[,1:4],Species)
View(dataset)
str(dataset)


# Atribuição do tipo fator à coluna especies (species) do dataset
cols <- c("Species")
dataset[cols] <- lapply(dataset[cols], factor)  ## as.factor() poderia ser usado
# Verificando o dataset
str(dataset)


# -------------------------------------------------------------------------------------------------------------------------
# Divisão do conjunto de dados em treinamento e teste 

# Para isso, vamos usar a função cretaDataPartition (parte caret) 
# similar a função sample - para podermos gerar partições (subconjuntos)
# sobre os dados, gerando os dados de treino e teste

# Essas são as classes que nós temos no dataset (não virginica e virginica)
species_iris <- dataset$Species
species_iris
unique(species_iris)

# É fundamental checar as dimensões (tamanhos) dos datasets para o split (divisão)
# a função dim nos informa a quantidade de linhas e colunas do dataset
size_dataset = dim(dataset)
size_dataset

# Para reprodução de resultados
set.seed(50)

# Divisão - split de dataset em treino e teste (p é a porcentagem relacionada ao treinamento)
indices_treinamento <- createDataPartition(dataset$Species, p = 0.9, list = FALSE)
indices_treinamento

# Agora, vamos usar os índices de treinamento para gerar o conjunto de dados de treinamento
dados_treinamento <-dataset[indices_treinamento,]
# Em seguida, podemos acessar diretamente o conjunto de teste
dados_teste <- dataset[-indices_treinamento,]

# Dicas:
# 1) repare na notação , usada no R para acessarmos todas as colunas do dataset via slicing []
# 2) o uso do sinal de - nos permite capturar diretamente o complemento dos índices de treino (i.e., teste)

# ----------------------------------------------------------------------------------------
# Exploração dos dados de treinamento com gráficos de dispersão 

# Gráfico de Dispersão com ggplot
ggplot(dados_treinamento, aes(x = dados_treinamento$Petal.Length, y = dados_treinamento$Petal.Width, color=Species)) + 
  geom_point() + 
  scale_color_discrete(name = "Legenda", labels = c("Não Virginica","Virginica"))+
  ylab('Width (largura)') + 
  xlab('Length (Comprimento)') + 
  ggtitle("Gráfico de Dispersão")
  
ggplot(data = dados_treinamento, aes(x=dados_treinamento$Petal.Length, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Comprimento (length)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 

ggplot(data = dados_treinamento, aes(x=dados_treinamento$Petal.Width, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Largura (width)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 

# Matriz de Correlação entre as Variáveis Explanatórias
feature_dataframe    = dados_treinamento[,1:4]
matrix_corr_features = cor(feature_dataframe)
View(matrix_corr_features)
corrplot(matrix_corr_features, method = 'color')

# Multicolinearidade
# https://www.tandfonline.com/doi/abs/10.1080/09720502.2010.10700699?journalCode=tjim20

# Contexto: correlação alta presente entre variáveis explicativas (explanatórias) do modelo
# Problema: tem impacto direto na estimação dos coeficientes do modelo
# Solução: identificação via matriz de correlação e análise 
# A multicolinearidade tem impacto direto na estimação dos coeficientes do modelo

# Problema específico: a multicolinearidade leva a um resultado instável de estimação para
# os coeficientes do modelo (vemos isso pelo aumento do erro/variância dos coeficientes)
# O VIF (variance inflator factor) é um indicador/fator plausível para reforçar a análise


# =======================================================================================================
# Construção do Modelo Preditivo com Regressão Logística

# Considerando - duas classes setosa e virginica

# Vamos criar o objeto referente à equação de relação de variáveis do modelo
equation <- " Species ~ ."
class(equation)
equation <- as.formula(equation)
class(equation)

# Dicas:
# 1) estamos criando uma fórmula no R 
# 2) do lado esquerdo do ~ colocamos a variável target ou resposta
# 3) do lado direito do ~ colocamos as variáveis explanatórias
# 4) quando usamos o . -> estamos apontando o uso de todas as variáveis explanatórias

# --------------------------------------------------------------------------------
# Treinamento do Modelo de Regressão Logística com todas as variáveis explicativas
?glm
modelo_ML_logistic <- glm(equation, data = dados_treinamento, family = 'binomial')
modelo_ML_logistic
# Síntese do modelo
summary(modelo_ML_logistic)

# -----------------------------------------------------------------------------------------------
# Realize predições para os dados de teste e obtenha a matriz de confusão dos resultados do modelo
previsao_teste <- predict(modelo_ML_logistic, dados_teste, type="response")
previsao_teste <- round(as.numeric(previsao_teste))
previsao_teste <- as.factor(previsao_teste)

dados_teste_fatores = as.factor(dados_teste$Species)
previsao_teste_data <- data.frame(previsao_teste, dados_teste_fatores)
confusionMatrix(data = previsao_teste, reference = dados_teste_fatores, positive = "1")

# Cômputo da acurácia
accuracy <- mean(dados_teste_fatores == previsao_teste)
accuracy


# --------------------------------------------------------------------------------
# Encontre as variáveis explanatórias mais relevantes para o modelo
modelo_ML_logistic_2 <- glm(Species ~ Petal.Width + Petal.Length, data = dados_treinamento, family = 'binomial')
modelo_ML_logistic_2
summary(modelo_ML_logistic_2)

# -----------------------------------------------------------------------------------------------
# Realize predições para os dados de teste e obtenha a matriz de confusão dos resultados do modelo
previsao_teste <- predict(modelo_ML_logistic_2, dados_teste, type="response")
previsao_teste <- round(as.numeric(previsao_teste))
previsao_teste <- as.factor(previsao_teste)

dados_teste_fatores = as.factor(dados_teste$Species)
previsao_teste_data <- data.frame(previsao_teste, dados_teste_fatores)
confusionMatrix(data = previsao_teste, reference = dados_teste_fatores, positive = "1")

# Cômputo da acurácia
accuracy_2 <- mean(dados_teste_fatores == previsao_teste)
accuracy_2
confusionMatrix(data = previsao_teste, reference = dados_teste_fatores, positive = "1")

# Acurácias
accuracy
accuracy_2

# --------------------------------------------------------------------------------
# Realize predições para essas duas espécies

flor1 <- data.frame(Sepal.Length=6.4, Sepal.Width=2.8, Petal.Length=4.6, Petal.Width=1.8)
flor2 <- data.frame(Sepal.Length=6.3, Sepal.Width=2.5, Petal.Length=4.1, Petal.Width=1.7)

pred_flor1 <- predict(modelo_ML_logistic, flor1, type = 'response') %>% as.numeric() %>% round()
pred_flor2 <- predict(modelo_ML_logistic, flor2, type = 'response') %>% as.numeric() %>% round()
pred_flor1
pred_flor2



