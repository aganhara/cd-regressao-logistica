---
title: "Exercício Computacional I"
author: "Anderson Ganhara"
date: "6/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Considere o conjunto de dados iris, amplamente conhecido e usado como exemplo em diversos livros de
aprendizagem de máquina. Esse conjunto já vem incorporado em diversos pacotes das linguagens R e Python, de
acordo com
Linguagem R: library(datasets)
Linguagem Python: from sklearn import datasets
A partir do conjunto de dados carregado capture somente os dados relacionados com a classe virginica, que
consiste em uma espécie de uma planta (flor). O objetivo desse exercício é construir um classificador binário a
partir de um modelo de regressão logística, permitindo verificar se uma espécie a ser testada é ou não do tipo
virginica. Isso significa que um pré-processamento deve ser realizado sobre o dataset iris a fim de obtermos
apenas duas classes (e.g., 0 -> não é virginica e 1 -> é virginica).
As variáveis explanatórias desse conhecido dataset são:
• Petal.Length: comprimento da pétala da flor
• Petal.Width: largura da pétala da flor
• Sepal.Length: comprimento da sépala da flor
• Sepal.Width: largura da sépala da flor
• Questões Avaliativas

– 1) Realize o pré-processamento necessário para extração dos dados relacionados à classe virginica.
```{r}

# =========================
# Exercicio Computacional 1

# Objetivo: implementar modelos de regressão logística no R

# Pacote com inúmeros métodos/técnicas de ML para a linguagem R
library(caret)

# Pacote com funções que nos auxiliam a entender métricas de desempenho de classificadores
library(ROCR)

# Pacote cm diversas funções relacionadas a modelos de classificação 
library(e1071)

# Pacote para que possamos trabalhar com diversos datasets tradicionais como o Iris
library(datasets) 

# Pacote para sínteses estatísticas (summary) dos modelos
library(skimr)

# Pacote para processamento de dados do R
library(dplyr)

# Usamos esse pacote para realizar a binarização de variáveis de saída com a função to.dummy
library(varhandle)

# Pacote para que possamos explorar a matriz de correlação entre variáveis explanatórias
library(corrplot)


dataset <- iris
summary(dataset)
```

```{r}
# Processando as classes para sua binarização do problema de classificação
# Objetivo: capturar as classes de interesse e atribuir 0 ou 1 para a espécie considerada no dataset
binary_species <- to.dummy(iris$Species, "species")
binary_species <- as.data.frame(binary_species)
unique(binary_species)
```

```{r}
# Espécies: setosa - versicolor - virginica
Species = binary_species$species.virginica %>% as.factor()
Species
dataset = data.frame(dataset[,1:4],Species)
```



– 2) Faça a análise de dados das variáveis explanatórias para o conjunto de dados.

```{r}
View(dataset)
str(dataset)
# Agora o dataset está classificado em virginica e nao virginica
unique(dataset$Species)
```

– 4) Para reprodução dos resultados use o set.seed(12).

```{r}
set.seed(12)

```

– 3) Realize a divisão do conjunto de treino e teste em 90/10.
```{r}
?createDataPartition
indices_treinamento <- createDataPartition(dataset$Species, p = 0.9, list = FALSE)
dados_treinamento <-dataset[indices_treinamento,]
dados_teste <- dataset[-indices_treinamento,]
```




– 5) Forneça visualizações de dispersão e densidades das variáveis explanatórias de treino e as classes.
```{r}
ggplot(dados_treinamento, aes(x = Petal.Length, y = Petal.Width, color=Species)) + 
  geom_point() + 
  scale_color_discrete(name = "Legenda", labels = c("Não Virginica", "Virginica"))+
  ylab('Width (largura)') + 
  xlab('Length (Comprimento)') + 
  ggtitle("Gráfico de Dispersão")
```


```{r}
ggplot(data = dados_treinamento, aes(x=Petal.Length, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Comprimento (length)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 
```

```{r}
ggplot(data = dados_treinamento, aes(x=Petal.Width, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Largura (width)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 
```
```{r}
feature_dataframe    = dados_treinamento[,1:4]
matrix_corr_features = cor(feature_dataframe)
corrplot(matrix_corr_features, method = 'color')
```
– 6) Construa e treine o modelo preditivo de ML baseado em regressão logística.
```{r}
equation <- " Species ~ ." %>% as.formula()
# modelo_ML_logistic <- glm("Species ~ .", data = dados_treinamento, family = 'binomial')
modelo_ML_logistic <- glm(equation, data = dados_treinamento, family = 'binomial')
```


– 7) Faça a síntese do modelo e interprete os seus resultados.
```{r}
summary(modelo_ML_logistic)
```


– 8) Encontre as variáveis explanatórias mais relevantes para o modelo.
```{r}
modelo_ML_logistic_2 <- glm(Species ~ Petal.Width + Petal.Length, data = dados_treinamento, family = 'binomial')
summary(modelo_ML_logistic_2)
```

– 9) Faça as predições para os dados de teste e avalie os resultados
```{r}
previsao_teste <- predict(modelo_ML_logistic_2, dados_teste, type="response") %>% as.numeric() %>% round() %>% as.factor()
previsao_teste_data <- data.frame(previsao_teste, dados_teste$Species)
confusionMatrix(data = previsao_teste, reference = dados_teste$Species, positive = "1")

#Houve uma acurácia de 86% 
```

– 10) A partir dos novos dados de entrada colocados abaixo, realize as classificações com o modelo:

flor1 <- data.frame(Sepal.Length=6.4, Sepal.Width=2.8, Petal.Length=4.6, Petal.Width=1.8)
flor2 <- data.frame(Sepal.Length=6.3, Sepal.Width=2.5, Petal.Length=4.1, Petal.Width=1.7)

```{r}
flor1 <- data.frame(Sepal.Length=6.4, Sepal.Width=2.8, Petal.Length=4.6, Petal.Width=1.8)
flor2 <- data.frame(Sepal.Length=6.3, Sepal.Width=2.5, Petal.Length=4.1, Petal.Width=1.7)
pred_flor1 <- predict(modelo_ML_logistic, flor1, type = 'response') %>% as.numeric() %>% round()
pred_flor2 <- predict(modelo_ML_logistic, flor2, type = 'response') %>% as.numeric() %>% round()
pred_flor1
pred_flor2
```